{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88254080-f128-446c-b563-54ebe8947a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as O\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device.upper()}\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee323ee7-0edb-428a-8b85-88ba93878aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = pd.read_csv(\"dataset.csv\")\n",
    "rawData=rawData.drop(columns=\"Time in s\")\n",
    "rawData[\"Angle\"] = rawData[\"Angle\"]*2\n",
    "whMapping = {\"Person A\":[50, 145], \"Person G\":[58, 168], \"Person F\":[78.6, 159], \"Person H\":[58, 168], \"Person E\": [75, 158], \"Person B\": [86, 166], \"Person C\": [65, 174], \"Person I\":[56, 160], \"Person J\":[65, 161], \"Person D\": [70, 161]}\n",
    "print(whMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7d4fd-ac86-4d14-b5f6-09dbc332e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3f801-33f7-4ee8-a640-1d6c59da69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Action coding:\n",
    "# 0 is idle state\n",
    "# 1 is flexion\n",
    "# -1 is extension\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "order=1\n",
    "fs=1\n",
    "cutoff=0.1\n",
    "sections = [[5,45, 1], [50,89, 0], [100,139, 1], [145,184, 0], [195,234, 1], [240,279, 0]]\n",
    "maxAngle=np.max(rawData[\"Angle\"])\n",
    "\n",
    "trainData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "             ,\"action\":[]\n",
    "             , \"angle\":[]\n",
    "            }\n",
    "\n",
    "testData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "             ,\"action\":[]\n",
    "             , \"angle\":[]\n",
    "            }\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.get_cmap(name, n)\n",
    "\n",
    "cmap = get_cmap(9)\n",
    "for idx, i in enumerate(list([\"Person A\",\"Person B\",\"Person G\",\"Person D\",\"Person E\",\"Person F\",\"Person H\",\"Person I\",\"Person J\"])):\n",
    "    iList = []\n",
    "    actList = []\n",
    "    angList = []\n",
    "    for sec in sections:\n",
    "        sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "        plt.plot(sig, color=cmap(idx))\n",
    "        iList.extend(sig)\n",
    "        actList.extend([sec[2]]*len(sig))\n",
    "        angList.extend(rawData[\"Angle\"][sec[1]-len(sig):sec[1]])\n",
    "    ln = len(iList)\n",
    "    trainData[\"current\"].extend(list(iList))\n",
    "    trainData[\"height\"].extend([whMapping[i][1]]*ln)\n",
    "    trainData[\"weight\"].extend([whMapping[i][0]]*ln)\n",
    "    trainData[\"action\"].extend(list(actList))\n",
    "    trainData[\"angle\"].extend(list(angList))\n",
    "\n",
    "for i in list([\"Person C\"]):\n",
    "    iList = []\n",
    "    actList = []\n",
    "    angList = []\n",
    "    for sec in sections:\n",
    "        sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "        iList.extend(sig)\n",
    "        actList.extend([sec[2]]*len(sig))\n",
    "        angList.extend(rawData[\"Angle\"][sec[1]-len(sig):sec[1]])\n",
    "    ln = len(iList)\n",
    "    testData[\"current\"].extend(list(iList))\n",
    "    testData[\"height\"].extend([whMapping[i][1]]*ln)\n",
    "    testData[\"weight\"].extend([whMapping[i][0]]*ln)\n",
    "    testData[\"action\"].extend(list(actList))\n",
    "    testData[\"angle\"].extend(list(angList))\n",
    "\n",
    "\n",
    "\n",
    "currentScaler = MinMaxScaler()\n",
    "a=np.array([*trainData[\"current\"], *testData[\"current\"]]).reshape((-1,1))\n",
    "print(a.shape)\n",
    "currentScaler.fit(a)\n",
    "trainData[\"current\"] = currentScaler.transform(np.array(trainData[\"current\"]).reshape((-1,1))).flatten()\n",
    "testData[\"current\"] = currentScaler.transform(np.array(testData[\"current\"]).reshape((-1,1))).flatten()\n",
    "# print(trainData)\n",
    "# print(testData)\n",
    "for i in trainData.keys():\n",
    "    print(i, len(trainData[i]))\n",
    "print()\n",
    "for i in testData.keys():\n",
    "    print(i, len(testData[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f714754-f124-40a4-9944-0c63a226a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(trainData)\n",
    "plt.plot(trainData[\"current\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31870b-eb6f-48e3-b45d-de6cdaeeebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pd.DataFrame.from_dict(trainData).corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2cee9d-ca84-4310-b998-899c01ee90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleDataset(Dataset):\n",
    "    def __init__(self, dataMap, device=\"cpu\"):\n",
    "        # super().__init__()\n",
    "        self.x=torch.tensor([dataMap[\"current\"],dataMap[\"height\"],dataMap[\"weight\"], dataMap[\"action\"]])\n",
    "        self.y=torch.tensor(dataMap[\"angle\"])\n",
    "        self.x = self.x.T\n",
    "        assert self.x.shape[0] == len(self.y), f\"X shape: {len(self.x)}, Y shape: {len(self.y)}\"\n",
    "        self.x=self.x.to(device)\n",
    "        self.x = self.x.to(torch.float)\n",
    "        self.y = self.y.to(device).to(torch.float)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df9cdc-7072-4d5c-81d5-451b87f11638",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset=AngleDataset(trainData, device)\n",
    "trainDL = DataLoader(trainDataset, shuffle=True, batch_size=16)\n",
    "print(len(trainDataset))\n",
    "\n",
    "testDataset = AngleDataset(testData, device)\n",
    "testDL = DataLoader(testDataset, shuffle=False, batch_size=1)\n",
    "print(len(testDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd5c2c-68b8-42ba-ba28-a18ba5d13bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, inputSize, hidden, outputSize):\n",
    "        super().__init__()\n",
    "        self.l1=nn.Linear(inputSize, hidden, bias=True)\n",
    "        self.l2=nn.Linear(hidden, hidden, bias=True)\n",
    "        self.l4=nn.Linear(hidden, outputSize, bias=True)\n",
    "\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.a2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        o1 = self.a1(self.l1(x))\n",
    "        o2 = self.a2(self.l2(o1))\n",
    "        return self.l4(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49168ccb-a23c-42e7-be03-68fe328ba2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lss = []\n",
    "testLss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f1c12-df13-47e5-9301-4bdeaf3c5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572e286-b0dd-40f9-bd1a-9e75f911eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = Model(4, 192, 1).to(device)\n",
    "opt = O.Adam(testModel.parameters(), lr=lr)\n",
    "sch = O.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "lossFn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a90336-8a0c-4160-a972-1925063dace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "minTestError = 100\n",
    "minTrainError = 100\n",
    "epoch = 0\n",
    "bestModelParams = None\n",
    "for e in tqdm(range(epochs)):\n",
    "    epochLoss=0\n",
    "    testModel.train()\n",
    "    for x, y in trainDL:\n",
    "        opt.zero_grad()\n",
    "        yHat = testModel(x).flatten()\n",
    "        l = lossFn(yHat, y)\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        epochLoss += l.detach().cpu().item()\n",
    "    lss.append(epochLoss/len(trainDL.dataset))\n",
    "    testModel.eval()\n",
    "    testError = 0\n",
    "    for xTest, yTest in testDL:\n",
    "        yTestHat = testModel(xTest).flatten()\n",
    "        testError += torch.abs(yTestHat - yTest).sum()\n",
    "    testError = testError.detach().cpu().item()/len(testDataset)\n",
    "    testLss.append(testError)\n",
    "    if testError < minTestError:\n",
    "        minTestError = testError\n",
    "        minTrainError = lss[-1]\n",
    "        epoch=e\n",
    "        bestModelParams = deepcopy(testModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae602c-6c2e-4914-b230-0c33919fdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lss[0:], label=\"Train Loss\")\n",
    "plt.plot(testLss[0:], label=\"Test Error\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best epoch at {epoch}\")\n",
    "print(f\"Least Train Error: {minTrainError:.3f}\")\n",
    "print(f\"Least Test Error: {minTestError:.3f}\")\n",
    "print()\n",
    "\n",
    "print(f\"Train Error %: {minTrainError*100/maxAngle:.3f}\")\n",
    "print(f\"Test  Error %: {minTestError*100/maxAngle:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e07d9e-c775-46c0-be62-a157863bfa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "testError = 0\n",
    "predData = []\n",
    "properData = []\n",
    "inpData = []\n",
    "for xTest, yTest in testDL:\n",
    "    yTestHat = bestModelParams(xTest).flatten()\n",
    "    predData.append(yTestHat.detach().cpu().item())\n",
    "    properData.append(yTest.detach().cpu().item())\n",
    "    inpData.append(xTest[0][0].detach().cpu().item())\n",
    "    testError += torch.abs(yTestHat - yTest).sum()\n",
    "testError = testError / len(testDataset)\n",
    "print(f\"Average Drift: {testError}\")\n",
    "print(f\"Error: {testError*100/maxAngle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3629f-fe8f-470c-862c-6e514ef7a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperData = [10860, 10870, 10880, 10938, 10852, 13944, 13628, 13940, 13998, 14278, 13880, 13524, 15342, 15240, 15480, 14486, 14654, 16584, 16066, 15286, 15726, 15968, 15562, 16102, 16018, 15988, 18776, 17688, 16440, 16128, 16722, 17270, 19036, 18220, 17224, 17822, 18668, 20788, 19418, 21644, 22008, 19586, 21194, 23806, 22608, 11440, 11508, 11394, 11334, 11354, 18718, 17524, 17614, 17804, 16712, 16344, 16154, 15166, 17034, 19100, 15414, 14716, 14844, 14068, 12858, 12702, 15384, 15258, 15106, 14306, 13972, 13510, 12632, 12422, 14316, 14162, 14758, 13798, 12656, 13364, 14536, 14162, 13206, 12180, 13744, 13658, 13098, 12268, 13662, 13710, 11000, 10988, 10912, 10918, 10918, 10896, 10896, 10888, 10916, 10880]\n",
    "weight = 65\n",
    "height = 174\n",
    "zeroAngleRange = range(0,5)\n",
    "ones = range(5, 43)\n",
    "topAngleRange = range(43, 52)\n",
    "zeros = range(52, 90)\n",
    "paperData = currentScaler.transform(np.array(paperData).reshape((-1, 1)))\n",
    "finalAngles=[]\n",
    "bestModelParams = bestModelParams.cpu()\n",
    "bestModelParams.eval()\n",
    "for i in range(len(paperData)):\n",
    "    if i in zeroAngleRange:\n",
    "        finalAngles.append(0)\n",
    "    elif i in ones:\n",
    "        pred = bestModelParams(torch.tensor(np.array([paperData[i][0], height, weight, 1])).float())\n",
    "        finalAngles.append(pred.item())\n",
    "    elif i in topAngleRange:\n",
    "        finalAngles.append(48.9)\n",
    "    elif i in zeros:\n",
    "        pred = bestModelParams(torch.tensor(np.array([paperData[i][0], height, weight, 0])).float())\n",
    "        finalAngles.append(pred.item())\n",
    "    else:\n",
    "        finalAngles.append(0)\n",
    "finalAngles = butter_lowpass_filter(finalAngles, fs=2, order=1, cutoff=0.1)\n",
    "plt.plot(finalAngles)\n",
    "print(finalAngles.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24958f5c-03d5-4e07-8984-fb8e3c50f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predData)\n",
    "plt.plot(properData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b3c67-e4f2-485d-a449-68a44157c94c",
   "metadata": {},
   "source": [
    "## K Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e85ec-18b8-44f6-a408-c76405e66a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for person in whMapping:\n",
    "    print(\"*\"*50)\n",
    "    print(f\"Test Subject: {person}\")\n",
    "    personList = list(whMapping.keys())\n",
    "    personList.remove(person)\n",
    "        \n",
    "    trainData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "                 ,\"action\":[]\n",
    "                 , \"angle\":[]\n",
    "                }\n",
    "    \n",
    "    testData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "                 ,\"action\":[]\n",
    "                 , \"angle\":[]\n",
    "                }\n",
    "    \n",
    "    for i in list(personList):\n",
    "        iList = []\n",
    "        actList = []\n",
    "        angList = []\n",
    "        for sec in sections:\n",
    "            sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "            # plt.plot(sig)\n",
    "            iList.extend(sig)\n",
    "            actList.extend([sec[2]]*len(sig))\n",
    "            angList.extend(rawData[\"Angle\"][sec[1]-len(sig):sec[1]])\n",
    "        ln = len(iList)\n",
    "        trainData[\"current\"].extend(list(iList))\n",
    "        trainData[\"height\"].extend([whMapping[i][1]]*ln)\n",
    "        trainData[\"weight\"].extend([whMapping[i][0]]*ln)\n",
    "        trainData[\"action\"].extend(list(actList))\n",
    "        trainData[\"angle\"].extend(list(angList))\n",
    "    \n",
    "    for i in list([person]):\n",
    "        iList = []\n",
    "        actList = []\n",
    "        angList = []\n",
    "        for sec in sections:\n",
    "            sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "            iList.extend(sig)\n",
    "            actList.extend([sec[2]]*len(sig))\n",
    "            angList.extend(rawData[\"Angle\"][sec[1]-len(sig):sec[1]])\n",
    "        ln = len(iList)\n",
    "        testData[\"current\"].extend(list(iList))\n",
    "        testData[\"height\"].extend([whMapping[i][1]]*ln)\n",
    "        testData[\"weight\"].extend([whMapping[i][0]]*ln)\n",
    "        testData[\"action\"].extend(list(actList))\n",
    "        testData[\"angle\"].extend(list(angList))\n",
    "    \n",
    "    \n",
    "    \n",
    "    currentScaler = MinMaxScaler()\n",
    "    a=np.array([*trainData[\"current\"], *testData[\"current\"]]).reshape((-1,1))\n",
    "    currentScaler.fit(a)\n",
    "    trainData[\"current\"] = currentScaler.transform(np.array(trainData[\"current\"]).reshape((-1,1))).flatten()\n",
    "    testData[\"current\"] = currentScaler.transform(np.array(testData[\"current\"]).reshape((-1,1))).flatten()\n",
    "    assert len(trainData[\"current\"]) == len(trainData[\"height\"]) == len(trainData[\"weight\"]) == len(trainData[\"action\"]) == len(trainData[\"angle\"]), \"train data not homogeneous\"\n",
    "    assert len(testData[\"current\"]) == len(testData[\"height\"]) == len(testData[\"weight\"]) == len(testData[\"action\"]) == len(testData[\"angle\"]), \"test data not homogeneous\"\n",
    "\n",
    "    print(f\"Train Len: {len(trainData[\"current\"])}, Test Len: {len(testData[\"current\"])}\")\n",
    "\n",
    "\n",
    "    trainDataset=AngleDataset(trainData, device)\n",
    "    trainDL = DataLoader(trainDataset, shuffle=True, batch_size=16)\n",
    "    \n",
    "    testDataset = AngleDataset(testData, device)\n",
    "    testDL = DataLoader(testDataset, shuffle=True, batch_size=16)\n",
    "\n",
    "    lss = []\n",
    "    testLss = []\n",
    "    testModel = Model(4, 192, 1).to(device)\n",
    "    opt = O.Adam(testModel.parameters(), lr=lr)\n",
    "    sch = O.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "    lossFn = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "    minTestError = 100\n",
    "    minTrainError = 100\n",
    "    epoch = 0\n",
    "    bestModelParams = None\n",
    "    for e in tqdm(range(epochs)):\n",
    "        epochLoss=0\n",
    "        testModel.train()\n",
    "        for x, y in trainDL:\n",
    "            opt.zero_grad()\n",
    "            yHat = testModel(x).flatten()\n",
    "            l = lossFn(yHat, y)\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "            epochLoss += l.detach().cpu().item()\n",
    "        lss.append(epochLoss/len(trainDL.dataset))\n",
    "        testModel.eval()\n",
    "        testError = 0\n",
    "        for xTest, yTest in testDL:\n",
    "            yTestHat = testModel(xTest).flatten()\n",
    "            testError += torch.abs(yTestHat - yTest).sum()\n",
    "        testError = testError.detach().cpu().item()/len(testDataset)\n",
    "        testLss.append(testError)\n",
    "        if testError < minTestError:\n",
    "            minTestError = testError\n",
    "            minTrainError = lss[-1]\n",
    "            epoch=e\n",
    "            bestModelParams = deepcopy(testModel)\n",
    "\n",
    "\n",
    "    plt.plot(lss[0:], label=\"Train Loss\")\n",
    "    plt.plot(testLss[0:], label=\"Test Error\")\n",
    "    plt.title(f\"Test: {person}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Best epoch at {epoch}\")\n",
    "    print(f\"Least Train Error: {minTrainError:.3f}\")\n",
    "    print(f\"Least Test Error: {minTestError:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"Train Error %: {minTrainError*100/maxAngle:.3f}\")\n",
    "    print(f\"Test  Error %: {minTestError*100/maxAngle:.3f}\")\n",
    "\n",
    "    testError = 0\n",
    "    bestModelParams.eval()\n",
    "    for xTest, yTest in testDL:\n",
    "        yTestHat = bestModelParams(xTest).flatten()\n",
    "        testError += torch.abs(yTestHat - yTest).sum()\n",
    "    testError = testError / len(testDataset)\n",
    "    print(f\"Average Drift: {testError}\")\n",
    "    print(f\"Error: {testError*100/maxAngle}\")\n",
    "\n",
    "    results.append([person, epoch, minTrainError, minTrainError*100/maxAngle, (testError).item(), (testError*100/maxAngle).item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94086a2-6761-419b-afa5-c779100200db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsPD  = pd.DataFrame(results)\n",
    "rsPD.columns = columns=[\"Person\", \"BestEpoch\", \"trainError\", \"TrainError%\", \"testError\", \"testError%\"]\n",
    "print(rsPD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
