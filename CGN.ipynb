{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88254080-f128-446c-b563-54ebe8947a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as O\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device.upper()}\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee323ee7-0edb-428a-8b85-88ba93878aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = pd.read_csv(\"dataset.csv\")\n",
    "rawData=rawData.drop(columns=\"Time in s\")\n",
    "whMapping = {\"Person A\":[50, 145], \"Person G\":[58, 168], \"Person F\":[78.6, 159], \"Person H\":[58, 168], \"Person E\": [75, 158], \"Person B\": [86, 166], \"Person C\": [65, 174], \"Person I\":[56, 160], \"Person J\":[65, 161], \"Person D\": [70, 161]}\n",
    "print(whMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7d4fd-ac86-4d14-b5f6-09dbc332e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3f801-33f7-4ee8-a640-1d6c59da69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action coding:\n",
    "# 1 is flexion\n",
    "# 0 is extension\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "order=1\n",
    "fs=1\n",
    "cutoff=0.1\n",
    "sections = [[5,44, 1], [50,89, 0], [100,139, 1], [145,184, 0], [195,234, 1], [240,279, 0]]\n",
    "\n",
    "\n",
    "trainFlexData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "             ,\"action\":[]\n",
    "            }\n",
    "\n",
    "testFlexData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "             ,\"action\":[]\n",
    "            }\n",
    "\n",
    "trainExtnData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "             ,\"action\":[]\n",
    "            }\n",
    "\n",
    "testExtnData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "             ,\"action\":[]\n",
    "            }\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.get_cmap(name, n)\n",
    "\n",
    "\n",
    "cmap = get_cmap(9)\n",
    "for idx, i in enumerate(list([\"Person A\",\"Person B\",\"Person G\",\"Person D\",\"Person E\",\"Person F\",\"Person H\",\"Person I\",\"Person J\"])):\n",
    "    for sec in sections:\n",
    "        if sec[2]==1:\n",
    "            continue\n",
    "        sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "        plt.plot(sig, color=cmap(idx))\n",
    "        trainFlexData[\"current\"].append(sig)\n",
    "        trainFlexData[\"height\"].append(whMapping[i][1])\n",
    "        trainFlexData[\"weight\"].append(whMapping[i][0])\n",
    "        trainFlexData[\"action\"].append(sec[2])\n",
    "\n",
    "\n",
    "for i in list([\"Person C\"]):\n",
    "    for sec in sections:\n",
    "        if sec[2] == 1:\n",
    "            continue\n",
    "        sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "        testFlexData[\"current\"].append(sig)\n",
    "        testFlexData[\"height\"].append(whMapping[i][1])\n",
    "        testFlexData[\"weight\"].append(whMapping[i][0])\n",
    "        testFlexData[\"action\"].append(sec[2])\n",
    "\n",
    "for idx, i in enumerate(list([\"Person A\",\"Person B\",\"Person G\",\"Person D\",\"Person E\",\"Person F\",\"Person H\",\"Person I\",\"Person J\"])):\n",
    "    for sec in sections:\n",
    "        if sec[2]==0:\n",
    "            continue\n",
    "        sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "        plt.plot(sig, color=cmap(idx))\n",
    "        trainExtnData[\"current\"].append(sig)\n",
    "        trainExtnData[\"height\"].append(whMapping[i][1])\n",
    "        trainExtnData[\"weight\"].append(whMapping[i][0])\n",
    "        trainExtnData[\"action\"].append(sec[2])\n",
    "\n",
    "\n",
    "for i in list([\"Person C\"]):\n",
    "    for sec in sections:\n",
    "        if sec[2] == 0:\n",
    "            continue\n",
    "        sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "        testExtnData[\"current\"].append(sig)\n",
    "        testExtnData[\"height\"].append(whMapping[i][1])\n",
    "        testExtnData[\"weight\"].append(whMapping[i][0])\n",
    "        testExtnData[\"action\"].append(sec[2])\n",
    "\n",
    "\n",
    "\n",
    "trainFlexData[\"current\"] = np.array(trainFlexData[\"current\"]) / 1000\n",
    "testFlexData[\"current\"] = np.array(testFlexData[\"current\"]) / 1000\n",
    "\n",
    "trainExtnData[\"current\"] = np.array(trainExtnData[\"current\"]) / 1000\n",
    "testExtnData[\"current\"] = np.array(testExtnData[\"current\"]) / 1000\n",
    "\n",
    "print(\"Flexion Statistics\")\n",
    "\n",
    "for i in trainFlexData.keys():\n",
    "    print(i, len(trainFlexData[i]))\n",
    "print(np.max(trainFlexData[\"current\"]))\n",
    "print(np.min(trainFlexData[\"current\"]))\n",
    "print()\n",
    "\n",
    "for i in testFlexData.keys():\n",
    "    print(i, len(testFlexData[i]))\n",
    "\n",
    "print()\n",
    "print(\"Extension Statistics\")\n",
    "\n",
    "for i in trainExtnData.keys():\n",
    "    print(i, len(trainExtnData[i]))\n",
    "print(np.max(trainExtnData[\"current\"]))\n",
    "print(np.min(trainExtnData[\"current\"]))\n",
    "print()\n",
    "\n",
    "for i in testExtnData.keys():\n",
    "    print(i, len(testExtnData[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2cee9d-ca84-4310-b998-899c01ee90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorDataset(Dataset):\n",
    "    def __init__(self, dataMap, device=\"cpu\"):\n",
    "        self.x = torch.tensor([dataMap[\"height\"], dataMap[\"weight\"]])\n",
    "        # , dataMap[\"action\"] # add to above tensor\n",
    "        self.y = torch.tensor(dataMap[\"current\"])\n",
    "        self.x = self.x.T\n",
    "        assert self.x.shape[0] == self.y.shape[0], f\"X shape: {len(self.x)}, Y shape: {len(self.y)}\"\n",
    "        self.x = self.x.to(device).to(torch.float)\n",
    "        self.y = self.y.to(device).to(torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b41814-3ef0-4a70-a42d-d77af88b38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize=8\n",
    "\n",
    "genTrainFlexData = GeneratorDataset(trainFlexData, device)\n",
    "genTrainFlexDataloader = DataLoader(genTrainFlexData, shuffle=True, batch_size=batchSize)\n",
    "\n",
    "genTestFlexData = GeneratorDataset(testFlexData, device)\n",
    "genTestFlexDataloader = DataLoader(genTestFlexData, shuffle=True, batch_size=batchSize)\n",
    "\n",
    "\n",
    "genTrainExtnData = GeneratorDataset(trainExtnData, device)\n",
    "genTrainExtnDataloader = DataLoader(genTrainExtnData, shuffle=True, batch_size=batchSize)\n",
    "\n",
    "genTestExtnData = GeneratorDataset(testExtnData, device)\n",
    "genTestExtnDataloader = DataLoader(genTestExtnData, shuffle=True, batch_size=batchSize)\n",
    "\n",
    "\n",
    "print(genTrainFlexData.x.shape, genTrainFlexData.y.shape, genTestFlexData.x.shape, genTestFlexData.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f48955f-aaab-4bec-a760-101abbe221b8",
   "metadata": {},
   "source": [
    "trainDataset=AngleDataset(trainData, device)\n",
    "trainDL = DataLoader(trainDataset, shuffle=True, batch_size=16)\n",
    "print(len(trainDataset))\n",
    "\n",
    "testDataset = AngleDataset(testData, device)\n",
    "testDL = DataLoader(testDataset, shuffle=True, batch_size=16)\n",
    "print(len(testDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd5c2c-68b8-42ba-ba28-a18ba5d13bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(inputSize, hiddenSize, bias=True)\n",
    "        self.l2 = nn.Linear(hiddenSize, hiddenSize, bias=True)\n",
    "        self.l3 = nn.Linear(hiddenSize, outputSize, bias=True)\n",
    "\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.a2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        o1 = self.a1(self.l1(x))\n",
    "        o2 = self.a2(self.l2(o1))\n",
    "\n",
    "        return self.l3(o2)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize):\n",
    "        super().__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(inputSize, hiddenSize, bias=True)\n",
    "        self.l2 = nn.Linear(hiddenSize, hiddenSize, bias=True)\n",
    "        self.l3 = nn.Linear(hiddenSize, outputSize, bias=False)\n",
    "\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.a3 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        o1 = self.a1(self.l1(x))\n",
    "        o2 = self.a2(self.l2(o1))\n",
    "\n",
    "        return self.a3(self.l3(o2))\n",
    "\n",
    "class CoE:\n",
    "    def __init__(self):\n",
    "        self.flexionGenerator = None\n",
    "        self.extensionGenerator = None\n",
    "\n",
    "    def load(self, flxGen, extGen):\n",
    "        self.flexionGenerator = flxGen\n",
    "        self.extensionGenerator = extGen\n",
    "        self.flexionGenerator.eval()\n",
    "        self.extensionGenerator.eval()\n",
    "\n",
    "    def __call__(self, x, action):\n",
    "        \"\"\"\n",
    "        action == 1 => flexion\n",
    "        action == 0 => extension\n",
    "        \"\"\"\n",
    "        if action == 1:\n",
    "            return self.flexionGenerator(x)\n",
    "        else:\n",
    "            return self.extensionGenerator(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f1c12-df13-47e5-9301-4bdeaf3c5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "lr=0.001\n",
    "noiseSize=34\n",
    "genLossFn = torch.nn.BCELoss()\n",
    "recLossFn = torch.nn.MSELoss()\n",
    "disLossFn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc003e06-4750-4006-b4f1-85273c3617ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(genNet, disNet, genTrainLoader, genTestLoader, genOPT, disOPT, genLossFn, disLossFn, recLossFn, epochs):\n",
    "    \"\"\"\n",
    "    returns train loss, test loss, best epoch and the best generator network\n",
    "    \"\"\"\n",
    "    disLoss = []\n",
    "    genLoss = []\n",
    "    supLoss = []\n",
    "    testGenError = []\n",
    "    disAcc=[]\n",
    "    minTestLoss = 10000\n",
    "    minTrainLoss = 10000\n",
    "    bestGenerator = None\n",
    "    for e in tqdm(range(epochs)):\n",
    "        genNet.train()\n",
    "        disNet.train()\n",
    "        rDisLoss = 0\n",
    "        rGenLoss = 0\n",
    "        rSupLoss = 0\n",
    "        rDisAcc=0\n",
    "        totalAllSamples=0\n",
    "        for gIN, gOUT in genTrainLoader:\n",
    "            # training discriminator\n",
    "            disNet.zero_grad()\n",
    "            genNet.zero_grad()\n",
    "            \n",
    "            realLabels = torch.ones((gIN.shape[0], 1)).to(device)\n",
    "            \n",
    "            gINWithNoise = torch.cat((gIN, torch.randn((gIN.shape[0], noiseSize)).to(device)), dim=1)\n",
    "            gOUTHat = genNet(gINWithNoise)\n",
    "            \n",
    "            genrLabels = torch.zeros(gIN.shape[0], 1).to(device)\n",
    "            \n",
    "            allSamples = torch.cat((gOUT, gOUTHat))\n",
    "            allSamplesLabels = torch.cat((realLabels, genrLabels))\n",
    "            \n",
    "            disPred = disNet(allSamples)\n",
    "\n",
    "            rDisAcc+=(disPred.round()==allSamplesLabels).sum().item()\n",
    "            totalAllSamples+=torch.numel(disPred)\n",
    "            predLoss = disLossFn(disPred, allSamplesLabels)\n",
    "            rDisLoss += predLoss.detach().cpu().item()\n",
    "            predLoss.backward()\n",
    "            disOPT.step()\n",
    "    \n",
    "            # # training generator\n",
    "            genNet.zero_grad()\n",
    "            gOUTHat1 = genNet(gINWithNoise)\n",
    "    \n",
    "            disOUTHat1 = disNet(gOUTHat1)\n",
    "            \n",
    "            unSupLoss = genLossFn(disOUTHat1, realLabels)\n",
    "            rGenLoss += unSupLoss.detach().cpu().item()\n",
    "            unSupLoss.backward()\n",
    "            genOPT.step()\n",
    "\n",
    "            # training generator with supervised loss            \n",
    "            genNet.zero_grad()\n",
    "            gOUTHat2 = genNet(gINWithNoise)\n",
    "            mseLoss = recLossFn(gOUTHat2, gOUT)\n",
    "            rSupLoss += mseLoss.detach().cpu().item()\n",
    "            mseLoss.backward()\n",
    "            genOPT.step()\n",
    "        disLoss.append(rDisLoss)\n",
    "        genLoss.append(rGenLoss)\n",
    "        supLoss.append(rSupLoss)\n",
    "        disAcc.append(rDisAcc/totalAllSamples)\n",
    "        genNet.eval()\n",
    "        testLoss = 0\n",
    "        for gIN, gOUT in genTestLoader:\n",
    "            gIN = torch.cat((gIN, torch.randn((gIN.shape[0], noiseSize)).to(device)), dim=1)\n",
    "            gOUTHat = genNet(gIN)\n",
    "            testLoss += torch.abs(gOUTHat - gOUT).sum()\n",
    "        testGenError.append((testLoss / len(genTestFlexData)).item())\n",
    "        if minTestLoss > testGenError[-1]:\n",
    "            bestGenerator = deepcopy(genNet)\n",
    "            minTestLoss = testGenError[-1]\n",
    "            epoch = e\n",
    "    return genLoss, disLoss, supLoss,disAcc, testGenError, e, bestGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70036e66-5f8f-4557-a1fc-b152d0735ab3",
   "metadata": {},
   "source": [
    "## Flexion Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572e286-b0dd-40f9-bd1a-9e75f911eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "genFlex = Generator(36, 256, 34).to(device)\n",
    "disFlex = Discriminator(34, 256, 1).to(device)\n",
    "# recFlex = Reconstructor(34, 512, 2).to(device)\n",
    "\n",
    "\n",
    "genOPTFlex = O.Adam(genFlex.parameters(), lr=lr)\n",
    "disOPTFlex = O.Adam(disFlex.parameters(), lr=lr)\n",
    "# recOPTFlex = O.Adam(recFlex.parameters(), lr=lr)\n",
    "# sch = O.lr_scheduler.StepLR(, step_size=10, gamma=0.5)\n",
    "\n",
    "# gen = Generator(36, 256, 34).to(device)\n",
    "# dis = Discriminator(34, 256, 1).to(device)\n",
    "# genOPT = O.Adam(gen.parameters(), lr=lr)\n",
    "# disOPT = O.Adam(dis.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d07ea-3512-4413-86a9-7ae0c11dda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGenLoss, trainDisLoss, trainSupLoss,disAcc, testGenLoss, bestFlexEpoch, bestFlexGenerator = train(genFlex, disFlex, genTrainFlexDataloader, genTestFlexDataloader, genOPTFlex, disOPTFlex, genLossFn, disLossFn, recLossFn, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae602c-6c2e-4914-b230-0c33919fdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainGenLoss[0:], label=\"Train Loss\")\n",
    "plt.plot(testGenLoss[0:], label=\"Test Error\")\n",
    "plt.title(\"Flexion Data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(disAcc)\n",
    "\n",
    "print(f\"Best epoch at {bestFlexEpoch}\")\n",
    "print(f\"Least Train Error: {min(trainGenLoss):.3f}\")\n",
    "print(f\"Least Test Error: {min(testGenLoss):.3f}\")\n",
    "print()\n",
    "\n",
    "# print(f\"Train Error %: {minTrainError*100/24.45:.3f}\")\n",
    "# print(f\"Test  Error %: {minTestError*100/24.45:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574ad4c-66d7-47d2-9ed0-463240f60215",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoss = 0\n",
    "for gIN, gOUT in genTestFlexDataloader:\n",
    "    gIN=torch.cat((gIN, torch.randn((gIN.shape[0], noiseSize)).to(device)), dim=1)\n",
    "    gOUTHat = bestFlexGenerator(gIN)\n",
    "    testLoss += torch.abs(gOUTHat - gOUT).sum()\n",
    "\n",
    "pointLoss = (testLoss /(len(genTestFlexDataloader.dataset)* len(genTestFlexData[0][1]))).item()\n",
    "print(\"Mean devaition:\", pointLoss)\n",
    "# print(\"Mean Error %\", pointLoss )\n",
    "\n",
    "\n",
    "height = 159.0\n",
    "weight = 68.0\n",
    "\n",
    "genFlex.eval()\n",
    "testInput = torch.cat((torch.tensor([height, weight]), torch.randn((noiseSize)))).to(device)\n",
    "act1Curve = bestFlexGenerator(testInput ).to(device)\n",
    "\n",
    "\n",
    "plt.plot(act1Curve.detach().cpu().tolist(), label=\"genr\")\n",
    "plt.plot(gOUT[2].cpu(), label=\"og data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234a017-fea7-492d-a89f-a66a925c64a6",
   "metadata": {},
   "source": [
    "## Extension Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2239ea-1d5b-4f7f-b0ea-1eb60ab80021",
   "metadata": {},
   "outputs": [],
   "source": [
    "genExtn = Generator(36, 256, 34).to(device)\n",
    "disExtn = Discriminator(34, 256, 1).to(device)\n",
    "\n",
    "genOPTExtn = O.Adam(genExtn.parameters(), lr=lr)\n",
    "disOPTExtn = O.Adam(disExtn.parameters(), lr=lr)\n",
    "# sch = O.lr_scheduler.StepLR(, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ff125-9984-4246-83b7-1c0b02ed1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGenExtnLoss, trainDisExtnLoss, trainSupExtnLoss, disExtnLoss, testGenExtnLoss, bestExtnEpoch, bestExtnGenerator = train(genExtn, disExtn, genTrainExtnDataloader, genTestExtnDataloader, genOPTExtn, disOPTExtn, genLossFn, disLossFn, recLossFn, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c2b9a-b103-4114-a2e2-1ecef007703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainGenExtnLoss[0:], label=\"Train Loss\")\n",
    "plt.plot(testGenExtnLoss[0:], label=\"Test Error\")\n",
    "plt.title(\"Extnion Data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(disAcc)\n",
    "\n",
    "print(f\"Best epoch at {bestExtnEpoch}\")\n",
    "print(f\"Least Train Error: {min(trainGenExtnLoss):.3f}\")\n",
    "print(f\"Least Test Error: {min(testGenExtnLoss):.3f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92ca88-6002-4c55-b9d4-45bb3cb58c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoss = 0\n",
    "for gIN, gOUT in genTestExtnDataloader:\n",
    "    gIN=torch.cat((gIN, torch.randn((gIN.shape[0], noiseSize)).to(device)), dim=1)\n",
    "    gOUTHat = bestExtnGenerator(gIN)\n",
    "    testLoss += torch.abs(gOUTHat - gOUT).sum()\n",
    "\n",
    "pointLoss = (testLoss / len(genTestExtnData[0][1])).item()\n",
    "print(\"Mean devaition:\", pointLoss)\n",
    "# print(\"Mean Error %\", pointLoss/ )\n",
    "\n",
    "\n",
    "height = 159.0\n",
    "weight = 68.0\n",
    "action1 = 1.0\n",
    "action0 = 0.0\n",
    "\n",
    "\n",
    "genExtn.eval()\n",
    "testInput = torch.cat((torch.tensor([height, weight]), torch.randn((noiseSize)))).to(device)\n",
    "act1Curve = bestExtnGenerator(testInput ).to(device)\n",
    "\n",
    "\n",
    "plt.plot(act1Curve.detach().cpu().tolist(), label=\"genr\")\n",
    "plt.plot(gOUT[0].cpu(), label=\"og data\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b3c67-e4f2-485d-a449-68a44157c94c",
   "metadata": {},
   "source": [
    "## K Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e85ec-18b8-44f6-a408-c76405e66a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "epochs = 200\n",
    "lr=0.001\n",
    "noiseSize=34\n",
    "batchSize = 8\n",
    "testBatchSize=1\n",
    "genLossFn = torch.nn.BCELoss()\n",
    "recLossFn = torch.nn.MSELoss()\n",
    "disLossFn = torch.nn.BCELoss()\n",
    "for person in [\"Person A\",\"Person B\",\"Person G\",\"Person D\",\"Person E\",\"Person F\",\"Person H\",\"Person I\",\"Person J\", \"Person C\"]:\n",
    "    print(\"*\"*50)\n",
    "    print(f\"Test Subject: {person}\")\n",
    "    personList = list(whMapping.keys())\n",
    "    personList.remove(person)\n",
    "\n",
    "\n",
    "    trainFlexData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "                 ,\"action\":[]\n",
    "                }\n",
    "    \n",
    "    testFlexData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "                 ,\"action\":[]\n",
    "                }\n",
    "    \n",
    "    trainExtnData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "                 ,\"action\":[]\n",
    "                }\n",
    "    \n",
    "    testExtnData = {\"weight\":[], \"height\":[], \"current\":[]\n",
    "                 ,\"action\":[]\n",
    "                }\n",
    "    \n",
    "    def get_cmap(n, name='hsv'):\n",
    "        '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "        RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "        return plt.get_cmap(name, n)\n",
    "    \n",
    "    \n",
    "    cmap = get_cmap(9)\n",
    "    for idx, i in enumerate(personList):\n",
    "        for sec in sections:\n",
    "            if sec[2]==0:\n",
    "                continue\n",
    "            sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "            # plt.plot(sig, color=cmap(idx))\n",
    "            trainFlexData[\"current\"].append(sig)\n",
    "            trainFlexData[\"height\"].append(whMapping[i][1])\n",
    "            trainFlexData[\"weight\"].append(whMapping[i][0])\n",
    "            trainFlexData[\"action\"].append(sec[2])\n",
    "    \n",
    "    \n",
    "    for i in list([person]):\n",
    "        for sec in sections:\n",
    "            if sec[2] == 0:\n",
    "                continue\n",
    "            sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "            testFlexData[\"current\"].append(sig)\n",
    "            testFlexData[\"height\"].append(whMapping[i][1])\n",
    "            testFlexData[\"weight\"].append(whMapping[i][0])\n",
    "            testFlexData[\"action\"].append(sec[2])\n",
    "    \n",
    "    for idx, i in enumerate(personList):\n",
    "        for sec in sections:\n",
    "            if sec[2]==1:\n",
    "                continue\n",
    "            sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "            # plt.plot(sig, color=cmap(idx))\n",
    "            trainExtnData[\"current\"].append(sig)\n",
    "            trainExtnData[\"height\"].append(whMapping[i][1])\n",
    "            trainExtnData[\"weight\"].append(whMapping[i][0])\n",
    "            trainExtnData[\"action\"].append(sec[2])\n",
    "    \n",
    "    \n",
    "    for i in list([person]):\n",
    "        for sec in sections:\n",
    "            if sec[2] == 1:\n",
    "                continue\n",
    "            sig = butter_lowpass_filter(rawData[i][sec[0]:sec[1]], cutoff, fs, order)[5:]\n",
    "            testExtnData[\"current\"].append(sig)\n",
    "            testExtnData[\"height\"].append(whMapping[i][1])\n",
    "            testExtnData[\"weight\"].append(whMapping[i][0])\n",
    "            testExtnData[\"action\"].append(sec[2])\n",
    "    \n",
    "    \n",
    "    \n",
    "    trainFlexData[\"current\"] = np.array(trainFlexData[\"current\"]) / 1000\n",
    "    testFlexData[\"current\"] = np.array(testFlexData[\"current\"]) / 1000\n",
    "    \n",
    "    trainExtnData[\"current\"] = np.array(trainExtnData[\"current\"]) / 1000\n",
    "    testExtnData[\"current\"] = np.array(testExtnData[\"current\"]) / 1000\n",
    "    \n",
    "    \n",
    "    # assert len(trainData[\"current\"]) == len(trainData[\"height\"]) == len(trainData[\"weight\"]) == len(trainData[\"action\"]) == len(trainData[\"angle\"]), \"train data not homogeneous\"\n",
    "    # assert len(testData[\"current\"]) == len(testData[\"height\"]) == len(testData[\"weight\"]) == len(testData[\"action\"]) == len(testData[\"angle\"]), \"test data not homogeneous\"\n",
    "\n",
    "    print(f\"Train Len: {len(trainFlexData[\"current\"])}, Test Len: {len(testFlexData[\"current\"])}\")\n",
    "\n",
    "    genTrainFlexData = GeneratorDataset(trainFlexData, device)\n",
    "    genTrainFlexDataloader = DataLoader(genTrainFlexData, shuffle=True, batch_size=batchSize)\n",
    "    \n",
    "    genTestFlexData = GeneratorDataset(testFlexData, device)\n",
    "    genTestFlexDataloader = DataLoader(genTestFlexData, shuffle=True, batch_size=testBatchSize)\n",
    "    \n",
    "    \n",
    "    genTrainExtnData = GeneratorDataset(trainExtnData, device)\n",
    "    genTrainExtnDataloader = DataLoader(genTrainExtnData, shuffle=True, batch_size=batchSize)\n",
    "    \n",
    "    genTestExtnData = GeneratorDataset(testExtnData, device)\n",
    "    genTestExtnDataloader = DataLoader(genTestExtnData, shuffle=True, batch_size=testBatchSize)\n",
    "\n",
    "    print(genTrainFlexData.x.shape)\n",
    "########### Flex Train and Test\n",
    "\n",
    "\n",
    "    genFlex = Generator(36, 256, 34).to(device)\n",
    "    disFlex = Discriminator(34, 256, 1).to(device)    \n",
    "    \n",
    "    genOPTFlex = O.Adam(genFlex.parameters(), lr=lr)\n",
    "    disOPTFlex = O.Adam(disFlex.parameters(), lr=lr)\n",
    "\n",
    "    trainGenFlexLoss, trainDisFlexLoss, trainSupFlexLoss, disAccFlex, testGenFlexLoss, bestFlexEpoch, bestFlexGenerator = train(genFlex, disFlex, genTrainFlexDataloader, genTestFlexDataloader, genOPTFlex, disOPTFlex, genLossFn, disLossFn, recLossFn, epochs)\n",
    "    trainGenExtnLoss, trainDisExtnLoss, trainSupExtnLoss, disAccExtn, testGenExtnLoss, bestExtnEpoch, bestExtnGenerator = train(genExtn, disExtn, genTrainExtnDataloader, genTestExtnDataloader, genOPTExtn, disOPTExtn, genLossFn, disLossFn, recLossFn, epochs)\n",
    "\n",
    "    plt.plot(trainGenFlexLoss[0:], label=\"Flex Train Error\")\n",
    "    plt.plot(testGenFlexLoss[0:], label=\"Flex Test Error\")\n",
    "    plt.plot(trainGenExtnLoss, label=\"Extn Train Error\")\n",
    "    plt.plot(testGenExtnLoss, label=\"Extn Test Error\")\n",
    "    plt.title(f\"Train and Test Loss for {person}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(disAccFlex, label=\"Flex Disc Acc\")\n",
    "    plt.plot(disAccExtn, label=\"Extn Disc Acc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(f\"Best Flex Train epoch at {bestFlexEpoch}\")\n",
    "    print(f\"Least Flex Train Error: {min(trainGenFlexLoss):.3f}\")\n",
    "    print(f\"Least Flex Test Error: {min(testGenFlexLoss):.3f}\")\n",
    "    print(f\"Avg Flex Dis Acc in last 20 epochs: {sum(disAccFlex[-20:])/20:.3f}\")\n",
    "    print()\n",
    "\n",
    "    print(f\"Best Extn Train epoch at {bestExtnEpoch}\")\n",
    "    print(f\"Least Extn Train Error: {min(trainGenExtnLoss):.3f}\")\n",
    "    print(f\"Least Extn Test Error: {min(testGenExtnLoss):.3f}\")\n",
    "    print(f\"Avg Extn Dis Acc in last 20 epochs: {sum(disAccExtn[-20:])/20:.3f}\")\n",
    "    print()\n",
    "    \n",
    "\n",
    "    testFlexLoss = 0\n",
    "    testExtnLoss = 0\n",
    "    for gIN, gOUTFlex in genTestFlexDataloader:\n",
    "        gIN=torch.cat((gIN, torch.randn((gIN.shape[0], noiseSize)).to(device)), dim=1)\n",
    "        gOUTFlexHat = bestFlexGenerator(gIN)\n",
    "        testFlexLoss += torch.abs(gOUTFlexHat - gOUTFlex).sum()\n",
    "    for gIN, gOUTExtn in genTestExtnDataloader:\n",
    "        gIN = torch.cat((gIN, torch.randn((gIN.shape[0], noiseSize)).to(device)), dim=1)\n",
    "        gOUTExtnHat = bestExtnGenerator(gIN)\n",
    "        testExtnLoss+= torch.abs(gOUTExtnHat - gOUTExtn).sum()\n",
    "\n",
    "    pointFlexLoss = (testFlexLoss /(len(genTestFlexDataloader.dataset)* len(genTestFlexData[0][1]))).item()\n",
    "    pointExtnLoss = (testExtnLoss /(len(genTestExtnDataloader.dataset)* len(genTestExtnData[0][1]))).item()\n",
    "    print(\"Mean flex devaition for the test patient:\", pointFlexLoss)\n",
    "    print(\"Mean extn devaition for the test patient:\", pointExtnLoss)\n",
    "    \n",
    "    genFlex.eval()\n",
    "    genExtn.eval()\n",
    "    \n",
    "    testInput = gIN\n",
    "    act1Curve = bestFlexGenerator(testInput).to(device)\n",
    "    act0Curve = bestExtnGenerator(testInput).to(device)\n",
    "    plt.plot(act0Curve.flatten().detach().cpu().tolist(), label=\"Extn Pred\")\n",
    "    plt.plot(act1Curve.flatten().detach().cpu().tolist(), label=\"Flex Pred\")\n",
    "    plt.plot(gOUTFlex.flatten().detach().cpu().tolist(), label=\"Flex Orig\")\n",
    "    plt.plot(gOUTExtn.flatten().detach().cpu().tolist(), label=\"Extn Orig\")\n",
    "    # plt.plot(gOUT[2].cpu(), label=\"OG Data\")\n",
    "    plt.title(f\"Test: {person}\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Power in W\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    ################\n",
    "    results.append([person, bestFlexEpoch, pointFlexLoss, sum(disAccFlex[-20:])/20, bestExtnEpoch, pointExtnLoss, sum(disAccExtn[-20:])/20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94086a2-6761-419b-afa5-c779100200db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsPD  = pd.DataFrame(results)\n",
    "rsPD.columns = columns=[\"Person\", \"BestFlexEpoch\", \"flexAvgLoss\", \"FlexAvgAcc\", \"BestExtnEpoch\", \"extnAvgLoss\", \"ExtnAvgAcc\"]\n",
    "print(rsPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b1a21-9501-44b7-bc08-53aaf42f6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    print(rsPD.loc[i][\"Person\"], \":\", \"{:.3f}\".format((rsPD.loc[i][\"flexAvgLoss\"]+ rsPD.loc[i][\"extnAvgLoss\"])/2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
